{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6155e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import requests\n",
    "import base64\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Show retriever Class\n",
    "class ShowRetriever:\n",
    "    def __init__(self):\n",
    "        self.show_id = None\n",
    "        self.client_id = \"6dae08f3c799496fad2adfe2657634a7\"\n",
    "        self.client_secret = \"2afb39d7abb84e7fa957c2ec76b8e6f4\"\n",
    "        self.auth_response = None\n",
    "        self.auth_header = base64.b64encode(f'{self.client_id}:{self.client_secret}'.encode()).decode('utf-8')\n",
    "        self.headers = {\n",
    "            'Authorization': f'Basic {self.auth_header}'\n",
    "        }\n",
    "        self.payload =  payload = {\n",
    "            'grant_type': 'client_credentials'\n",
    "        }\n",
    "        self.descs = []\n",
    "        self.titles = []\n",
    "        self.dates = []\n",
    "        \n",
    "    #url = f'https://api.spotify.com/v1/shows/{show_id}/episodes?offset=1&limit=20'\n",
    "        \n",
    "    def authenticate(self):\n",
    "        \n",
    "       \n",
    "        response = requests.post('https://accounts.spotify.com/api/token', data=self.payload, headers=self.headers)\n",
    "        \n",
    "        self.auth_response = response\n",
    "\n",
    "    def retrieve_episodes(self, show, offset, limit):\n",
    "        \n",
    "        while self.auth_response.status_code != 200:\n",
    "            self.authenticate()\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "    \n",
    "        url = f'https://api.spotify.com/v1/shows/{show}/episodes?offset={offset}&limit={limit}'\n",
    "        access_token = self.auth_response.json()['access_token']\n",
    "        #print(access_token)\n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers)\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            show_data = response.json()\n",
    "            for episode in show_data[\"items\"]:\n",
    "                if type(episode) is not type(None):\n",
    "                    self.descs.append(episode['description'])\n",
    "                    self.titles.append(episode['name'])\n",
    "                    self.dates.append(episode['release_date'])\n",
    "            \n",
    "        else:\n",
    "            print(self.show_id)\n",
    "            print(f\"{self.show_id} gives {response}\")\n",
    "            \n",
    "        return response\n",
    "    \n",
    "    def retrieve_all(self):\n",
    "        offset=0\n",
    "        limit=50\n",
    "        response = self.retrieve_episodes(self.show_id, offset, limit)\n",
    "        while response.status_code != 404:\n",
    "            offset += limit\n",
    "            response = self.retrieve_episodes(self.show_id, offset, limit)\n",
    "            \n",
    "            \n",
    "# Function to run NLP/NER only if the word Podcast exists in the description\n",
    "def ner_on_descs(desc):\n",
    "    result = nlp(desc)\n",
    "    return result\n",
    "\n",
    "\n",
    "def show_search_by_name(name):\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "    show_id = None\n",
    "    show_name = None\n",
    "    if len(name) > 0:\n",
    "        search_query = name.replace(' ', '%2B')\n",
    "    else:\n",
    "        return (show_id, show_name)\n",
    "    client_id='6dae08f3c799496fad2adfe2657634a7'\n",
    "    client_secret='2afb39d7abb84e7fa957c2ec76b8e6f4'\n",
    "    \n",
    "    #show_id = '4rOoJ6Egrf8K2IrywzwOMk'\n",
    "    url = f'https://api.spotify.com/v1/search?q={search_query}&type=show&market=US&limit=10'\n",
    "    #url = 'https://api.spotify.com/v1/search?q=JRE&type=show'\n",
    "    auth_header = base64.b64encode(f'{client_id}:{client_secret}'.encode()).decode('utf-8')\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Basic {auth_header}'\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        'grant_type': 'client_credentials'\n",
    "    }\n",
    "    response = requests.post('https://accounts.spotify.com/api/token', data=payload, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        access_token = response.json()['access_token']\n",
    "        \n",
    "        headers = {\n",
    "            'Authorization': f'Bearer {access_token}'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            show_data = response.json()\n",
    "            #print(search_query)\n",
    "           # print(show_data)\n",
    "            if len(show_data['shows']['items']) > 0:\n",
    "                #print(len(show_data['shows']['items']))\n",
    "                try:\n",
    "                    show_id = show_data['shows']['items'][0]['id']\n",
    "                    show_name = show_data['shows']['items'][0]['name']\n",
    "                except TypeError:\n",
    "                    show_id = None\n",
    "                    show_name = None\n",
    "        else:\n",
    "            print(f\"Error: Unable to retrieve show information. Status code {response.status_code}\")\n",
    "    else:\n",
    "        print(f\"Error: Unable to retrieve access token. Status code {response.status_code}\")\n",
    "        \n",
    "    return (show_id, show_name)\n",
    "\n",
    "with open(\"podcasters.pkl\", \"rb\") as f:\n",
    "podcasters = pickle.load(f)\n",
    "\n",
    "filter = [ x for x in names if len(x)>0]\n",
    "single = [x[0] for x in filter]\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "import fuzzywuzzy\n",
    "\n",
    "def find_closest_match(query_name,name_list=podcasters, threshold=100):\n",
    "    \"\"\"\n",
    "    Find the closest match to 'query_name' in 'name_list'.\n",
    "    \n",
    "    :param name_list: List of names to search.\n",
    "    :param query_name: Name to search for.\n",
    "    :param threshold: The minimum score for a match (0-100, where 100 is an exact match).\n",
    "    :return: Closest match name and its score, or None if no match above the threshold.\n",
    "    \"\"\"\n",
    "    # Use the 'extractOne' method to find the closest match\n",
    "    if query_name is not None:\n",
    "        best_match = process.extractOne(query_name, name_list, score_cutoff=threshold,scorer= fuzzywuzzy.fuzz.token_set_ratio)\n",
    "        if best_match:\n",
    "            return best_match[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def name_extraction_from_ner(ner_results):\n",
    "    output = ner_results\n",
    "    \n",
    "    person_names = []\n",
    "    current_name = \"\"\n",
    "    if output != '':\n",
    "        for i, token in enumerate(output):\n",
    "            if token['entity'] in ['B-PER', 'I-PER'] and not token['word'].startswith('##'):\n",
    "                current_name += ' '\n",
    "            if token[\"entity\"] in [\"B-PER\", \"I-PER\"]:\n",
    "                current_name += token['word'].replace('##', '')\n",
    "        \n",
    "            if i == len(output) - 1 or (i + 1 < len(output) and output[i + 1]['entity'] not in ['I-PER', 'B-PER']):\n",
    "                if current_name:\n",
    "                    person_names.append(current_name.strip())  # Strip leading and trailing spaces before appending\n",
    "                    current_name = \"\"\n",
    "        \n",
    "    #print(\"Extracted Person Names:\", person_names)\n",
    "    return person_names\n",
    "    \n",
    "SR = ShowRetriever()\n",
    "SR.authenticate()\n",
    "SR.show_id = '4rOoJ6Egrf8K2IrywzwOMk'\n",
    "SR.retrieve_all()\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-large-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "df = pd.read_pickle(\"JRE_DF.pkl\")\n",
    "\n",
    "from queue import Queue\n",
    "processed_ids = set()  # Initialize an empty set to keep track of processed IDs\n",
    "final_df = pd.DataFrame(columns=['OriginShow', 'Showname', 'PodcastHosts', 'GuestShowSpotifyId'])\n",
    "\n",
    "\n",
    "def process_single_id(id_number, showname, queue):\n",
    "    if id_number in processed_ids and id_number is not None:\n",
    "        return  # Skip if the ID has already been processed\n",
    "\n",
    "    SR = ShowRetriever()\n",
    "    SR.authenticate()\n",
    "    SR.show_id = id_number\n",
    "    SR.retrieve_all()\n",
    "    \n",
    "    num_processes = 3\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        results = pool.map(ner_on_descs, SR.descs)\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        names = pool.map(name_extraction_from_ner, results)\n",
    "\n",
    "    guests_and_dates = pd.DataFrame({'Guest':names, 'Dates':SR.dates})\n",
    "    print(guests_and_dates)\n",
    "    \n",
    "    filter = [ x for x in names if len(x)>0]\n",
    "    single = [x[0] for x in filter]\n",
    "    with Pool(num_processes) as pool:\n",
    "        # Use pool.map to apply the function to each item in the list\n",
    "        matches = pool.map(find_closest_match, single)\n",
    "        matches = list(set([x for x in matches if x is not None]))\n",
    "        matches =  [s.split(' (')[0] for s in matches if s is not None]\n",
    "        #print(matches)\n",
    "\n",
    "    with Pool(num_processes) as pool:\n",
    "        search_results = pool.map(show_search_by_name, matches)\n",
    "        guest_show_names = np.transpose(list(search_results))[1]\n",
    "        guest_show_ids = np.transpose(list(search_results))[0]\n",
    "\n",
    "    showname_list = [showname for _ in range(len(show_ids))]\n",
    "    temp_df = pd.DataFrame(list(zip(showname_list, guest_show_names, matches, guest_show_ids, guests_and_dates)),\n",
    "                           columns=['OriginShow', 'Showname', 'PodcastHosts', 'GuestShowSpotifyId', 'guests_and_dates'])\n",
    "    print(temp_df)\n",
    "    global final_df\n",
    "    final_df = pd.concat([final_df, temp_df], ignore_index=True)\n",
    "\n",
    "    processed_ids.add(id_number)  # Add the current ID to the set of processed IDs, as to not use the same ID twice\n",
    "    \n",
    "    for new_id, new_showname in zip(guest_show_ids, guest_show_names): # Recursion\n",
    "        if new_id is None:\n",
    "            continue\n",
    "        else:\n",
    "            queue.put((new_id, new_showname))\n",
    "\n",
    "def ids_to_descs(ids: list, start_podcast: str):\n",
    "    queue = Queue()\n",
    "    \n",
    "    # Add initial IDs to the queue\n",
    "    for id_number in ids:\n",
    "        if id_number is not None:\n",
    "            queue.put((id_number, start_podcast))\n",
    "    print(queue)\n",
    "    while not queue.empty():\n",
    "        id_number, showname = queue.get()\n",
    "        print(\"QUEUEGET\",id_number, showname)\n",
    "        process_single_id(id_number, showname, queue)\n",
    "        \n",
    "\n",
    "ids_to_descs(podcast_ids, \"The Joe Rogan Experience\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb7182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4rOoJ6Egrf8K2IrywzwOMk\n",
      "4rOoJ6Egrf8K2IrywzwOMk gives <Response [404]>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd48f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
